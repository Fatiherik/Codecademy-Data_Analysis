{\rtf1\ansi\ansicpg1252\cocoartf2511
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;\f1\fnil\fcharset0 HelveticaNeue;\f2\fnil\fcharset0 HelveticaNeue-Italic;
\f3\froman\fcharset0 Times-Roman;\f4\fnil\fcharset0 HelveticaNeue-Bold;\f5\fmodern\fcharset0 Courier;
}
{\colortbl;\red255\green255\blue255;\red56\green56\blue56;\red255\green255\blue255;\red164\green191\blue255;
\red23\green23\blue23;\red252\green115\blue96;\red117\green255\blue242;\red254\green219\blue112;\red0\green0\blue0;
\red129\green131\blue134;\red19\green19\blue20;\red0\green0\blue0;}
{\*\expandedcolortbl;;\cssrgb\c28235\c28235\c28235;\cssrgb\c100000\c100000\c100000;\cssrgb\c70196\c80000\c100000;
\cssrgb\c11765\c11765\c11765;\cssrgb\c100000\c53725\c45098;\cssrgb\c51373\c100000\c96078;\cssrgb\c100000\c87843\c51373;\cssrgb\c0\c1\c1;
\cssrgb\c57647\c58431\c59608;\cssrgb\c9804\c9804\c10196;\cssrgb\c0\c0\c0;}
{\*\listtable{\list\listtemplateid1\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{none\}}{\leveltext\leveltemplateid1\'00;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid1}}
{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}}
\paperw11900\paperh16840\margl1440\margr1440\vieww28600\viewh18000\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs24 \cf0 \'97 
\f1\fs35\fsmilli17600 \cf2 \cb3 \expnd0\expndtw0\kerning0
We can test this using a\'a0
\f2\i univariate T-test
\f1\i0 . A univariate T-test compares a sample mean to a hypothetical population mean. It answers the question \'93What is the probability that the sample came from a distribution with the desired mean?\'94\
\pard\pardeftab720\sl560\sa240\partightenfactor0
\cf2 When we conduct a hypothesis test, we want to first create a\'a0
\f2\i null hypothesis
\f1\i0 , which is a prediction that there is no significant difference. The null hypothesis that this test examines can be phrased as such: \'93The set of samples belongs to a population with the target mean\'94.\
The result of the 1 Sample T Test is a\'a0
\f2\i p-value
\f1\i0 , which will tell us whether or not we can reject this null hypothesis. Generally, if we receive a p-value of less than 0.05, we can reject the null hypothesis and state that there is a significant difference.\
\pard\pardeftab720\sl440\partightenfactor0

\f3\fs28\fsmilli14080 \cf4 \cb5 from\cf3  \cf6 scipy\cf3 .\cf7 stats\cf3  \cf4 import\cf3  \cf6 ttest_1samp\cf3 \cb1 \
\cf4 \cb5 import\cf3  \cf6 numpy\cf3  \cf4 as\cf3  \cf6 np\cf3 \cb1 \
\
\cf6 \cb5 ages\cf3  = \cf6 np\cf3 .\cf7 genfromtxt\cf3 (\cf8 "ages.csv"\cf3 )\cb1 \
\cb5 print(\cf6 ages\cf3 )\cb1 \
\cf6 \cb5 ages_mean\cf3 =\cf6 np\cf3 .\cf7 mean\cf3 (\cf6 ages\cf3 )				ort 31 cikti\cb1 \
\cb5 print(\cf6 ages_mean\cf3 )\cb1 \
\cf6 \cb5 tstat\cf3 , \cf6 pval\cf3  = \cf6 ttest_1samp\cf3 (\cf6 ages\cf3 , \cf6 30\cf3 )\cb1 \
\cb5 print \cf6 pval						p-value 0,56 cikti\cf3 \cb1 \
\
\pard\pardeftab720\sl440\partightenfactor0
\cf9 ** null hypothesis iki mean ayni diye yaz\uc0\u305 l\u305 yor, e\u287 er p value 0.05 ten k\'fc\'e7\'fckse null hypo reddediliyor, burda p value buyuk cikti yani null reddedilemez yani mean var aynidir,, zaten biri 30 digeri 31.\
\'97 \cf4 \cb5 from\cf3  \cf6 scipy\cf3 .\cf7 stats\cf3  \cf4 import\cf3  \cf6 ttest_1samp\cf3 \cb1 \
\pard\pardeftab720\sl440\partightenfactor0
\cf4 \cb5 import\cf3  \cf6 numpy\cf3  \cf4 as\cf3  \cf6 np\cf3 \cb1 \
\
\cf6 \cb5 correct_results\cf3  = \cf6 0\cf3  \cf10 # Start the counter at 0\cf3 \cb1 \
\
\cf6 \cb5 daily_visitors\cf3  = \cf6 np\cf3 .\cf7 genfromtxt\cf3 (\cf8 "daily_visitors.csv"\cf3 , \cf6 delimiter\cf3 =\cf8 ","\cf3 )\cb1 \
\
\cf4 \cb5 for\cf3  \cf6 i\cf3  \cf4 in\cf3  range(\cf6 1000\cf3 ): \cf10 # 1000 experiments\cf3 \cb1 \
\cb5    \cf10 #your ttest here:\cf3 \cb1 \
\cb5    \cb1 \
\cb5    \cf10 #print the pvalue here:\cf3 \cb1 \
\cb5    \cf6 tstat\cf3 , \cf6 pval\cf3  = \cf6 ttest_1samp\cf3 (\cf6 daily_visitors\cf3 [\cf6 i\cf3 ], \cf6 30\cf3 )				one sample t-test\cb1 \
\cb5    \cf4 if\cf3  \cf6 pval<0.05\cf3 :\cb1 \
\cb5       \cf6 correct_results\cf3 +=\cf6 1\cf3 \cb1 \
\cb5   \cb1 \
\cb5 print \cf8 "We correctly recognized that the distribution was different in "\cf3  + str(\cf6 correct_results\cf3 ) + \cf8 " out of 1000 experiments."\cf3 \cb1 \
\cb5 print \cf8 "We correctly recognized that the distribution was different in "\cf3  + str(\cf6 correct_results\cf3 ) + \cf8 " out of 1000 experiments."\
\
\'97 \cf4 from\cf3  \cf6 scipy\cf3 .\cf7 stats\cf3  \cf4 import\cf3  \cf6 ttest_ind\cf3 \cb1 \
\cf4 \cb5 import\cf3  \cf6 numpy\cf3  \cf4 as\cf3  \cf6 np\cf3 \cb1 \
\
\cf6 \cb5 week1\cf3  = \cf6 np\cf3 .\cf7 genfromtxt\cf3 (\cf8 "week1.csv"\cf3 ,  \cf6 delimiter\cf3 =\cf8 ","\cf3 )\cb1 \
\cf6 \cb5 week2\cf3  = \cf6 np\cf3 .\cf7 genfromtxt\cf3 (\cf8 "week2.csv"\cf3 ,  \cf6 delimiter\cf3 =\cf8 ","\cf3 )\cb1 \
\
\cf6 \cb5 week1_mean\cf3 =\cf6 np\cf3 .\cf7 mean\cf3 (\cf6 week1\cf3 )\cb1 \
\cf6 \cb5 week2_mean\cf3 =\cf6 np\cf3 .\cf7 mean\cf3 (\cf6 week2\cf3 )\cb1 \
\cb5 print(\cf6 week1_mean\cf3 ,\cf6 week2_mean\cf3 )\cb1 \
\
\cf6 \cb5 week1_std\cf3 =\cf6 np\cf3 .\cf7 std\cf3 (\cf6 week1\cf3 )\cb1 \
\cf6 \cb5 week2_std\cf3 =\cf6 np\cf3 .\cf7 std\cf3 (\cf6 week2\cf3 )\cb1 \
\cb5 print(\cf6 week1_std\cf3 ,\cf6 week2_std\cf3 )\cb1 \
\
\cf6 \cb5 tstatstic\cf3 , \cf6 pval\cf3  = \cf6 ttest_ind\cf3 (\cf6 week1\cf3 , \cf6 week2\cf3 )				2 sample t-test\cb1 \
\cb5 print(\cf6 pval\cf3 )\
\
\'97\cf4 from\cf3  \cf6 scipy\cf3 .\cf7 stats\cf3  \cf4 import\cf3  \cf6 ttest_ind\cf3 \cb1 \
\cf4 \cb5 import\cf3  \cf6 numpy\cf3  \cf4 as\cf3  \cf6 np\cf3 \cb1 \
\
\cf6 \cb5 a\cf3  = \cf6 np\cf3 .\cf7 genfromtxt\cf3 (\cf8 "store_a.csv"\cf3 ,  \cf6 delimiter\cf3 =\cf8 ","\cf3 )\cb1 \
\cf6 \cb5 b\cf3  = \cf6 np\cf3 .\cf7 genfromtxt\cf3 (\cf8 "store_b.csv"\cf3 ,  \cf6 delimiter\cf3 =\cf8 ","\cf3 )\cb1 \
\cf6 \cb5 c\cf3  = \cf6 np\cf3 .\cf7 genfromtxt\cf3 (\cf8 "store_c.csv"\cf3 ,  \cf6 delimiter\cf3 =\cf8 ","\cf3 )\cb1 \
\
\cf6 \cb5 a_mean\cf3 =\cf6 np\cf3 .\cf7 mean\cf3 (\cf6 a\cf3 )\cb1 \
\cf6 \cb5 b_mean\cf3 =\cf6 np\cf3 .\cf7 mean\cf3 (\cf6 b\cf3 )\cb1 \
\cf6 \cb5 c_mean\cf3 =\cf6 np\cf3 .\cf7 mean\cf3 (\cf6 c\cf3 )\cb1 \
\
\cf6 \cb5 a_std\cf3 =\cf6 np\cf3 .\cf7 std\cf3 (\cf6 a\cf3 )\cb1 \
\cf6 \cb5 b_std\cf3 =\cf6 np\cf3 .\cf7 std\cf3 (\cf6 b\cf3 )\cb1 \
\cf6 \cb5 c_std\cf3 =\cf6 np\cf3 .\cf7 std\cf3 (\cf6 c\cf3 )\cb1 \
\
\cf6 \cb5 tstatstic\cf3 , \cf6 a_b_pval\cf3 = \cf6 ttest_ind\cf3 (\cf6 a\cf3 ,\cf6 b\cf3 ) \cb1 \
\cf6 \cb5 tstatstic\cf3 , \cf6 a_c_pval\cf3 = \cf6 ttest_ind\cf3 (\cf6 a\cf3 ,\cf6 c\cf3 ) \cb1 \
\cf6 \cb5 tstatstic\cf3 , \cf6 b_c_pval\cf3 = \cf6 ttest_ind\cf3 (\cf6 b\cf3 ,\cf6 c\cf3 ) \cb1 \
\cb5 print(\cf6 a_b_pval\cf3 )\cb1 \
\cb5 print(\cf6 a_c_pval\cf3 )\cb1 \
\cb5 print(\cf6 b_c_pval\cf3 )\cb1 \
\
\cf6 \cb5 error_prob\cf3 =\cf6 1-0.95\cf3 **\cf6 3					3 veri icin ayr\uc0\u305  ayr\u305  3 tane 2-sample test uygulamak mant\u305 kl\u305  degil \'e7\'fcnk\'fc  hata olasiligi art\u305 yor, normalde 0,05 idi simdi 0,14(1-0.95**3) oldu, bunun icin ANOVA yi kullanaca\u287 \u305 z.\cf3 \cb1 \
\cb5 print(\cf6 error_prob\cf3 )\cb1 \
\
\cf8 \cb5 \'97\cf4 from\cf3  \cf6 scipy\cf3 .\cf7 stats\cf3  \cf4 import\cf3  \cf6 ttest_ind\cf3 \cb1 \
\cf4 \cb5 from\cf3  \cf6 scipy\cf3 .\cf7 stats\cf3  \cf4 import\cf3  \cf6 f_oneway\cf3 \cb1 \
\cf4 \cb5 import\cf3  \cf6 numpy\cf3  \cf4 as\cf3  \cf6 np\cf3 \cb1 \
\
\cf6 \cb5 a\cf3  = \cf6 np\cf3 .\cf7 genfromtxt\cf3 (\cf8 "store_a.csv"\cf3 ,  \cf6 delimiter\cf3 =\cf8 ","\cf3 )\cb1 \
\cf6 \cb5 b\cf3  = \cf6 np\cf3 .\cf7 genfromtxt\cf3 (\cf8 "store_b_new.csv"\cf3 ,  \cf6 delimiter\cf3 =\cf8 ","\cf3 )\cb1 \
\cf6 \cb5 c\cf3  = \cf6 np\cf3 .\cf7 genfromtxt\cf3 (\cf8 "store_c.csv"\cf3 ,  \cf6 delimiter\cf3 =\cf8 ","\cf3 )\cb1 \
\
\cf6 \cb5 fstat\cf3 , \cf6 pval\cf3  = \cf6 f_oneway\cf3 (\cf6 a\cf3 ,\cf6 b\cf3 ,\cf6 c\cf3 )					ANOVA yontemi- ikiden fazla verinin mean ayni mi degil mi test etmek icin.\cb1 \
\
\cb5 print(\cf6 pval\cf3 )\
\
\'97
\f1\fs35\fsmilli17600 \cf2 \cb3 After using only ANOVA, we can\'92t make any conclusions on which two populations have a significant difference.
\f3\fs28\fsmilli14080 \cf3 \cb5 \
\
\'97\cf4 import\cf3  \cf6 codecademylib\cf3 \cb1 \
\cf4 \cb5 import\cf3  \cf6 numpy\cf3  \cf4 as\cf3  \cf6 np\cf3 \cb1 \
\cf4 \cb5 import\cf3  \cf6 matplotlib\cf3 .\cf7 pyplot\cf3  \cf4 as\cf3  \cf6 plt\cf3 \cb1 \
\
\cf6 \cb5 dist_1\cf3  = \cf6 np\cf3 .\cf7 genfromtxt\cf3 (\cf8 "1.csv"\cf3 ,  \cf6 delimiter\cf3 =\cf8 ","\cf3 )\cb1 \
\cf6 \cb5 dist_2\cf3  = \cf6 np\cf3 .\cf7 genfromtxt\cf3 (\cf8 "2.csv"\cf3 ,  \cf6 delimiter\cf3 =\cf8 ","\cf3 )\cb1 \
\cf6 \cb5 dist_3\cf3  = \cf6 np\cf3 .\cf7 genfromtxt\cf3 (\cf8 "3.csv"\cf3 ,  \cf6 delimiter\cf3 =\cf8 ","\cf3 )\cb1 \
\cf6 \cb5 dist_4\cf3  = \cf6 np\cf3 .\cf7 genfromtxt\cf3 (\cf8 "4.csv"\cf3 ,  \cf6 delimiter\cf3 =\cf8 ","\cf3 )\cb1 \
\
\pard\pardeftab720\sl440\partightenfactor0
\cf10 \cb5 #plot your histogram here\cf3 \cb1 \
\pard\pardeftab720\sl440\partightenfactor0
\cf6 \cb5 plt\cf3 .\cf7 hist\cf3 (\cf6 dist_4\cf3 )\cb1 \
\cf6 \cb5 plt\cf3 .\cf7 show\cf3 ()\cb1 \
\
\cf6 \cb5 not_normal\cf3 =\cf6 4\cf3 \cb1 \
\
\cf6 \cb5 ratio\cf3 =\cf6 np\cf3 .\cf7 std\cf3 (\cf6 dist_2\cf3 )/\cf6 np\cf3 .\cf7 std\cf3 (\cf6 dist_3\cf3 )\cb1 \
\cb5 print(\cf6 ratio\cf3 )\cb1 \
\
\cf8 \cb5 \
\pard\pardeftab720\sl480\sa180\partightenfactor0

\f4\b\fs39 \cf11 \cb3 Assumptions of Numerical Hypothesis Tests\
\pard\pardeftab720\sl420\sa240\partightenfactor0

\f1\b0\fs26\fsmilli13200 \cf2 Before we use numerical hypothesis tests, we need to be sure that the following things are true:\cb1 \
\pard\pardeftab720\sl360\sa360\partightenfactor0

\f4\b\fs33\fsmilli16800 \cf11 \cb3 1. The samples should each be normally distributed\'85ish\cb1 \
\pard\pardeftab720\sl420\sa240\partightenfactor0

\f1\b0\fs26\fsmilli13200 \cf2 \cb3 Data analysts in the real world often still perform hypothesis on sets that aren\'92t exactly normally distributed. What is more important is to recognize if there is some reason to believe that a normal distribution is especially unlikely. If your dataset is definitively not normal, the numerical hypothesis tests won\'92t work as intended.\cb1 \
\cb3 For example, imagine we have three datasets, each representing a day of traffic data in three different cities. Each dataset is independent, as traffic in one city should not impact traffic in another city. However, it is unlikely that each dataset is normally distributed. In fact, each dataset probably has two distinct peaks, one at the morning rush hour and one during the evening rush hour. The histogram of a day of traffic data might look something like this:\cb1 \
\pard\pardeftab720\sl440\partightenfactor0

\f3\fs28\fsmilli14080 \cf8 \cb5 \
\pard\pardeftab720\sl560\sa240\partightenfactor0

\f1\fs35\fsmilli17600 \cf2 \cb3 In this scenario, using a numerical hypothesis test would be inappropriate.\
\pard\pardeftab720\sl360\sa360\partightenfactor0

\f4\b\fs33\fsmilli16800 \cf11 2. The population standard deviations of the groups should be equal\
\pard\pardeftab720\sl560\sa240\partightenfactor0

\f1\b0\fs35\fsmilli17600 \cf2 For ANOVA and 2-Sample T-Tests, using datasets with standard deviations that are significantly different from each other will often obscure the differences in group means.\
To check for similarity between the standard deviations, it is normally sufficient to divide the two standard deviations and see if the ratio is \'93close enough\'94 to 1. \'93Close enough\'94 may differ in different contexts but generally staying within 10% should suffice.\
\pard\pardeftab720\sl360\sa360\partightenfactor0

\f4\b\fs33\fsmilli16800 \cf11 3. The samples must be independent\
\pard\pardeftab720\sl560\sa240\partightenfactor0

\f1\b0\fs35\fsmilli17600 \cf2 When comparing two or more datasets, the values in one distribution should not affect the values in another distribution. In other words, knowing more about one distribution should not give you any information about any other distribution.\
Here are some examples where it would seem the samples are not independent:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl560\sa120\partightenfactor0
\ls1\ilvl0\cf2 \kerning1\expnd0\expndtw0 		\expnd0\expndtw0\kerning0
the number of goals scored per soccer player before, during, and after undergoing a rigorous training regimen\cb1 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl560\sa240\partightenfactor0
\ls1\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 		\expnd0\expndtw0\kerning0
a group of patients\'92 blood pressure levels before, during, and after the administration of a drug\cb1 \
\pard\pardeftab720\sl560\partightenfactor0
\cf2 \cb3 It is important to understand your datasets before you begin conducting hypothesis tests on it so that you know you are choosing the right test.\
\
\'97 
\f3\fs28\fsmilli14080 \cf4 \cb5 from\cf3  \cf6 statsmodels\cf3 .\cf7 stats\cf6 .\cf7 multicomp\cf3  \cf4 import\cf3  \cf6 pairwise_tukeyhsd\cf3 \cb1 \
\pard\pardeftab720\sl440\partightenfactor0
\cf4 \cb5 from\cf3  \cf6 scipy\cf3 .\cf7 stats\cf3  \cf4 import\cf3  \cf6 f_oneway\cf3 \cb1 \
\cf4 \cb5 import\cf3  \cf6 numpy\cf3  \cf4 as\cf3  \cf6 np\cf3 \cb1 \
\
\cf6 \cb5 a\cf3  = \cf6 np\cf3 .\cf7 genfromtxt\cf3 (\cf8 "store_a.csv"\cf3 ,  \cf6 delimiter\cf3 =\cf8 ","\cf3 )\cb1 \
\cf6 \cb5 b\cf3  = \cf6 np\cf3 .\cf7 genfromtxt\cf3 (\cf8 "store_b.csv"\cf3 ,  \cf6 delimiter\cf3 =\cf8 ","\cf3 )\cb1 \
\cf6 \cb5 c\cf3  = \cf6 np\cf3 .\cf7 genfromtxt\cf3 (\cf8 "store_c.csv"\cf3 ,  \cf6 delimiter\cf3 =\cf8 ","\cf3 )\cb1 \
\
\cf6 \cb5 stat\cf3 , \cf6 pval\cf3  = \cf6 f_oneway\cf3 (\cf6 a\cf3 , \cf6 b\cf3 , \cf6 c\cf3 )\cb1 \
\cb5 print \cf6 pval\cf3 \cb1 \
\
\pard\pardeftab720\sl440\partightenfactor0
\cf10 \cb5 # Using our data from ANOVA, we create v and l\cf3 \cb1 \
\pard\pardeftab720\sl440\partightenfactor0
\cf6 \cb5 v\cf3  = \cf6 np\cf3 .\cf7 concatenate\cf3 ([\cf6 a\cf3 , \cf6 b\cf3 , \cf6 c\cf3 ])\cb1 \
\cf6 \cb5 labels\cf3  = [\cf8 'a'\cf3 ] * len(\cf6 a\cf3 ) + [\cf8 'b'\cf3 ] * len(\cf6 b\cf3 ) + [\cf8 'c'\cf3 ] * len(\cf6 c\cf3 )\cb1 \
\
\cf6 \cb5 tukey_results\cf3  = \cf6 pairwise_tukeyhsd\cf3 (\cf6 v\cf3 , \cf6 labels\cf3 , \cf6 0.05\cf3 )			ANOVA da hangi iki mean ayni olmadigini g\'f6remiyorduk, tukey\'92s range test ile g\'f6rebiliyoruz. \cb1 \
\cb5 print(\cf6 tukey_results\cf3 )\cb1 \
\cf8 \cb5 \
\'97
\f5\fs24 \cf3 \cb12 Multiple Comparison of Means - Tukey HSD,FWER=0.05\
\pard\pardeftab720\sl280\partightenfactor0
\cf3 =============================================\
group1 group2 meandiff  lower   upper  reject\
---------------------------------------------\
  a      b     7.2767   3.2266 11.3267  True \
  a      c     4.0115  -0.0385  8.0616 False \
  b      c    -3.2651  -7.3152  0.7849 False \cf2 \
\pard\pardeftab720\sl440\partightenfactor0

\f3\fs28\fsmilli14080 \cf8 \cb5 \
\'97 
\f1\fs35\fsmilli17600 \cf2 \cb3 So far, we have been working with numerical datasets. The tests we have looked at, the 1- and 2-Sample T-Tests, ANOVA, and Tukey\'92s Range test, will not work if we can\'92t find the means of our distributions and compare them.\
\pard\pardeftab720\sl560\sa240\partightenfactor0
\cf2 If we have a dataset where the entries are not numbers, but categories instead, we have to use different methods.\
To analyze a dataset like this, with two different possibilities for entries, we can use a\'a0
\f2\i Binomial Test
\f1\i0 . A Binomial Test compares a categorical dataset to some expectation.\
\pard\pardeftab720\sl440\partightenfactor0

\f3\fs28\fsmilli14080 \cf8 \cb5 \
\cf4 \'97from\cf3  \cf6 scipy\cf3 .\cf7 stats\cf3  \cf4 import\cf3  \cf6 binom_test\cf3 \cb1 \
\cf6 \cb5 pval\cf3  = \cf6 binom_test\cf3 (\cf6 510\cf3 , \cf6 n\cf3 =\cf6 10000\cf3 , \cf6 p\cf3 =\cf6 0.06\cf3 )\cb1 \
\cb5 print(\cf6 pval\cf3 )\cb1 \
\
\cf6 \cb5 pval2\cf3  = \cf6 binom_test\cf3 (\cf6 590\cf3 , \cf6 n\cf3 =\cf6 10000\cf3 , \cf6 p\cf3 =\cf6 0.06\cf3 )\cb1 \
\cb5 print(\cf6 pval2\cf3 )\cb1 \
\cf8 \cb5 \
\'97
\f1\fs35\fsmilli17600 \cf2 \cb3 \'a0If we have two or more categorical datasets that we want to compare, we should use a Chi Square test. In this case, the null hypothesis is that there\'92s no significant difference between the datasets. We reject that hypothesis, and state that there is a significant difference between two of the datasets if we get a p-value less than 0.05.\
\

\f3\fs28\fsmilli14080 \cf8 \cb5 \
\cf4 from\cf3  \cf6 scipy\cf3 .\cf7 stats\cf3  \cf4 import\cf3  \cf6 chi2_contingency\cf3 \cb1 \
\
\pard\pardeftab720\sl440\partightenfactor0
\cf10 \cb5 # 		Contingency table\cf3 \cb1 \
\cf10 \cb5 #         	toy-1 |  toy-2\cf3 \cb1 \
\cf10 \cb5 # ----+------------------+------------\cf3 \cb1 \
\cf10 \cb5 # 1st gr |       30       |  10\cf3 \cb1 \
\cf10 \cb5 # 2nd gr |      35       |  5\cf3 \cb1 \
\cf10 \cb5 # 3rd gr |      28       |  12\cf3 \cb1 \
\
\pard\pardeftab720\sl440\partightenfactor0
\cf6 \cb5 X\cf3  = [[\cf6 30\cf3 , \cf6 10\cf3 ],\cb1 \
\cb5      [\cf6 35\cf3 , \cf6 5\cf3 ],\cb1 \
\cb5      [\cf6 28\cf3 , \cf6 12\cf3 ]]\cb1 \
\cf6 \cb5 chi2\cf3 , \cf6 pval\cf3 , \cf6 dof\cf3 , \cf6 expected\cf3  = \cf6 chi2_contingency\cf3 (\cf6 X\cf3 )\cb1 \
\cb5 print \cf6 pval\cf3 \cb1 \
\cf8 \cb5 \
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\cf3 \cb1 \
}