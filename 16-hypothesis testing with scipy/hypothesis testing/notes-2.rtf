— We can test this using a univariate T-test. A univariate T-test compares a sample mean to a hypothetical population mean. It answers the question “What is the probability that the sample came from a distribution with the desired mean?”
When we conduct a hypothesis test, we want to first create a null hypothesis, which is a prediction that there is no significant difference. The null hypothesis that this test examines can be phrased as such: “The set of samples belongs to a population with the target mean”.
The result of the 1 Sample T Test is a p-value, which will tell us whether or not we can reject this null hypothesis. Generally, if we receive a p-value of less than 0.05, we can reject the null hypothesis and state that there is a significant difference.
from scipy.stats import ttest_1samp
import numpy as np

ages = np.genfromtxt("ages.csv")
print(ages)
ages_mean=np.mean(ages)				ort 31 cikti
print(ages_mean)
tstat, pval = ttest_1samp(ages, 30)
print pval						p-value 0,56 cikti

** null hypothesis iki mean ayni diye yazılıyor, eğer p value 0.05 ten küçükse null hypo reddediliyor, burda p value buyuk cikti yani null reddedilemez yani mean var aynidir,, zaten biri 30 digeri 31.
— from scipy.stats import ttest_1samp
import numpy as np

correct_results = 0 # Start the counter at 0

daily_visitors = np.genfromtxt("daily_visitors.csv", delimiter=",")

for i in range(1000): # 1000 experiments
   #your ttest here:
   
   #print the pvalue here:
   tstat, pval = ttest_1samp(daily_visitors[i], 30)				one sample t-test
   if pval<0.05:
      correct_results+=1
  
print "We correctly recognized that the distribution was different in " + str(correct_results) + " out of 1000 experiments."
print "We correctly recognized that the distribution was different in " + str(correct_results) + " out of 1000 experiments."

— from scipy.stats import ttest_ind
import numpy as np

week1 = np.genfromtxt("week1.csv",  delimiter=",")
week2 = np.genfromtxt("week2.csv",  delimiter=",")

week1_mean=np.mean(week1)
week2_mean=np.mean(week2)
print(week1_mean,week2_mean)

week1_std=np.std(week1)
week2_std=np.std(week2)
print(week1_std,week2_std)

tstatstic, pval = ttest_ind(week1, week2)				2 sample t-test
print(pval)

—from scipy.stats import ttest_ind
import numpy as np

a = np.genfromtxt("store_a.csv",  delimiter=",")
b = np.genfromtxt("store_b.csv",  delimiter=",")
c = np.genfromtxt("store_c.csv",  delimiter=",")

a_mean=np.mean(a)
b_mean=np.mean(b)
c_mean=np.mean(c)

a_std=np.std(a)
b_std=np.std(b)
c_std=np.std(c)

tstatstic, a_b_pval= ttest_ind(a,b) 
tstatstic, a_c_pval= ttest_ind(a,c) 
tstatstic, b_c_pval= ttest_ind(b,c) 
print(a_b_pval)
print(a_c_pval)
print(b_c_pval)

error_prob=1-0.95**3					3 veri icin ayrı ayrı 3 tane 2-sample test uygulamak mantıklı degil çünkü  hata olasiligi artıyor, normalde 0,05 idi simdi 0,14(1-0.95**3) oldu, bunun icin ANOVA yi kullanacağız.
print(error_prob)

—from scipy.stats import ttest_ind
from scipy.stats import f_oneway
import numpy as np

a = np.genfromtxt("store_a.csv",  delimiter=",")
b = np.genfromtxt("store_b_new.csv",  delimiter=",")
c = np.genfromtxt("store_c.csv",  delimiter=",")

fstat, pval = f_oneway(a,b,c)					ANOVA yontemi- ikiden fazla verinin mean ayni mi degil mi test etmek icin.

print(pval)

—After using only ANOVA, we can’t make any conclusions on which two populations have a significant difference.

—import codecademylib
import numpy as np
import matplotlib.pyplot as plt

dist_1 = np.genfromtxt("1.csv",  delimiter=",")
dist_2 = np.genfromtxt("2.csv",  delimiter=",")
dist_3 = np.genfromtxt("3.csv",  delimiter=",")
dist_4 = np.genfromtxt("4.csv",  delimiter=",")

#plot your histogram here
plt.hist(dist_4)
plt.show()

not_normal=4

ratio=np.std(dist_2)/np.std(dist_3)
print(ratio)


Assumptions of Numerical Hypothesis Tests
Before we use numerical hypothesis tests, we need to be sure that the following things are true:
1. The samples should each be normally distributed…ish
Data analysts in the real world often still perform hypothesis on sets that aren’t exactly normally distributed. What is more important is to recognize if there is some reason to believe that a normal distribution is especially unlikely. If your dataset is definitively not normal, the numerical hypothesis tests won’t work as intended.
For example, imagine we have three datasets, each representing a day of traffic data in three different cities. Each dataset is independent, as traffic in one city should not impact traffic in another city. However, it is unlikely that each dataset is normally distributed. In fact, each dataset probably has two distinct peaks, one at the morning rush hour and one during the evening rush hour. The histogram of a day of traffic data might look something like this:

In this scenario, using a numerical hypothesis test would be inappropriate.
2. The population standard deviations of the groups should be equal
For ANOVA and 2-Sample T-Tests, using datasets with standard deviations that are significantly different from each other will often obscure the differences in group means.
To check for similarity between the standard deviations, it is normally sufficient to divide the two standard deviations and see if the ratio is “close enough” to 1. “Close enough” may differ in different contexts but generally staying within 10% should suffice.
3. The samples must be independent
When comparing two or more datasets, the values in one distribution should not affect the values in another distribution. In other words, knowing more about one distribution should not give you any information about any other distribution.
Here are some examples where it would seem the samples are not independent:
		the number of goals scored per soccer player before, during, and after undergoing a rigorous training regimen
		a group of patients’ blood pressure levels before, during, and after the administration of a drug
It is important to understand your datasets before you begin conducting hypothesis tests on it so that you know you are choosing the right test.

— from statsmodels.stats.multicomp import pairwise_tukeyhsd
from scipy.stats import f_oneway
import numpy as np

a = np.genfromtxt("store_a.csv",  delimiter=",")
b = np.genfromtxt("store_b.csv",  delimiter=",")
c = np.genfromtxt("store_c.csv",  delimiter=",")

stat, pval = f_oneway(a, b, c)
print pval

# Using our data from ANOVA, we create v and l
v = np.concatenate([a, b, c])
labels = ['a'] * len(a) + ['b'] * len(b) + ['c'] * len(c)

tukey_results = pairwise_tukeyhsd(v, labels, 0.05)			ANOVA da hangi iki mean ayni olmadigini göremiyorduk, tukey’s range test ile görebiliyoruz. 
print(tukey_results)

—Multiple Comparison of Means - Tukey HSD,FWER=0.05
=============================================
group1 group2 meandiff  lower   upper  reject
---------------------------------------------
  a      b     7.2767   3.2266 11.3267  True 
  a      c     4.0115  -0.0385  8.0616 False 
  b      c    -3.2651  -7.3152  0.7849 False 

— So far, we have been working with numerical datasets. The tests we have looked at, the 1- and 2-Sample T-Tests, ANOVA, and Tukey’s Range test, will not work if we can’t find the means of our distributions and compare them.
If we have a dataset where the entries are not numbers, but categories instead, we have to use different methods.
To analyze a dataset like this, with two different possibilities for entries, we can use a Binomial Test. A Binomial Test compares a categorical dataset to some expectation.

—from scipy.stats import binom_test
pval = binom_test(510, n=10000, p=0.06)
print(pval)

pval2 = binom_test(590, n=10000, p=0.06)
print(pval2)

— If we have two or more categorical datasets that we want to compare, we should use a Chi Square test. In this case, the null hypothesis is that there’s no significant difference between the datasets. We reject that hypothesis, and state that there is a significant difference between two of the datasets if we get a p-value less than 0.05.


from scipy.stats import chi2_contingency

# 		Contingency table
#         	toy-1 |  toy-2
# ----+------------------+------------
# 1st gr |       30       |  10
# 2nd gr |      35       |  5
# 3rd gr |      28       |  12

X = [[30, 10],
     [35, 5],
     [28, 12]]
chi2, pval, dof, expected = chi2_contingency(X)
print pval






























